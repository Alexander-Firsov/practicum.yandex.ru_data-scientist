{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid Chocolate 2px; padding: 40px\">\n",
    "\n",
    "–ü—Ä–∏–≤–µ—Ç, –º–µ–Ω—è –∑–æ–≤—É—Ç –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ö—É–∏–º–æ–≤. –Ø –±—É–¥—É —Ä–µ–≤—å—é–µ—Ä–æ–º —Ç–≤–æ–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞. –¢—ã –º–æ–∂–µ—à—å –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫–æ –º–Ω–µ –Ω–∞ \"—Ç—ã\"üòè –ù–∞–¥–µ—é—Å—å, —Ç–µ–±—è —Ç–∞–∫–∂–µ –Ω–µ —Å–º—É—Ç–∏—Ç, –µ—Å–ª–∏ —è –±—É–¥—É –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ —Ç–µ–±–µ –Ω–∞ \"—Ç—ã\", –Ω–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ—É–¥–æ–±–Ω–æ, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º!\n",
    "\n",
    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–µ —É–¥–∞–ª—è–π –º–æ–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –æ–Ω–∏ –±—É–¥—É—Ç –æ—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ª–µ–∑–Ω—ã –¥–ª—è –Ω–∞—à–µ–π —Ä–∞–±–æ—Ç—ã –≤ —Å–ª—É—á–∞–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–µ–∫—Ç–∞. \n",
    "\n",
    "–¢—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ—à—å —Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –º–æ–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ —Å–≤–æ–∏–º–∏ –ø–æ —à–∞–±–ª–æ–Ω—É, –ø–æ–∫–∞–∑–∞–Ω–Ω–æ–º—É —á—É—Ç—å –Ω–∏–∂–µ. –≠—Ç–æ –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã –Ω–µ —Å–æ–∑–¥–∞–≤–∞–ª–∞—Å—å –ø—É—Ç–∞–Ω–∏—Ü–∞üòâ\n",
    "\n",
    "–¢—ã –º–æ–∂–µ—à—å –Ω–∞–π—Ç–∏ –º–æ–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –æ–±–æ–∑–Ω–∞—á–µ–Ω–Ω—ã–µ <font color='green'>–∑–µ–ª–µ–Ω—ã–º</font>, <font color='gold'>–∂–µ–ª—Ç—ã–º</font> –∏ <font color='red'>–∫—Ä–∞—Å–Ω—ã–º</font> —Ü–≤–µ—Ç–∞–º–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä:\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:</b> –í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º —à–∞–≥–µ —è–≤–ª—è–µ—Ç—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º.\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>\n",
    "    \n",
    "<b>–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏üí°:</b> –í —Å–ª—É—á–∞–µ, –∫–æ–≥–¥–∞ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º —à–∞–≥–µ —Å—Ç–∞–Ω–µ—Ç –µ—â–µ –ª—É—á—à–µ, –µ—Å–ª–∏ –≤–Ω–µ—Å—Ç–∏ –Ω–µ–±–æ–ª—å—à–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–∏–≤—ã.\n",
    "</div>\n",
    "\n",
    "\n",
    "<br/>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"></h2>\n",
    "\n",
    "    \n",
    "<b>–ù–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—Éü§î:</b>\n",
    " –í —Å–ª—É—á–∞–µ, –∫–æ–≥–¥–∞ —Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º —à–∞–≥–µ —Ç—Ä–µ–±—É–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∏ –∏ –≤–Ω–µ—Å–µ–Ω–∏—è –ø—Ä–∞–≤–æ–∫. –ù–∞–ø–æ–º–∏–Ω–∞—é, —á—Ç–æ –ø—Ä–æ–µ–∫—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏–Ω—è—Ç —Å –ø–µ—Ä–≤–æ–≥–æ —Ä–∞–∑–∞, –µ—Å–ª–∏ —Ä–µ–≤—å—é —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, —Ä–µ–∫–æ–º–µ–Ω–¥—É—é—â–∏–µ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å —à–∞–≥–∏.\n",
    "</div>\n",
    "    \n",
    "    \n",
    "<br/>    \n",
    "<div class=\"alert alert-info\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞: <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>üëã:</b> –í —Ç–∞–∫–æ–π —Ü–≤–µ—Ç–æ–≤–æ–π —è—á–µ–π–∫–µ —è –ø—Ä–æ—à—É —Ç–µ–±—è –æ—Å—Ç–∞–≤–ª—è—Ç—å —Å–≤–æ–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏. –ï—Å–ª–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—à—å –ø—Ä–æ–µ–∫—Ç –Ω–∞ –≤—Ç–æ—Ä–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏ –∏ –≤—ã—à–µ, –Ω–µ –∑–∞–±—ã–≤–∞–π –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–æ–º–µ—Ä –∏—Ç–µ—Ä–∞—Ü–∏–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä, \"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞ v.2\".\n",
    "</div> \n",
    "\n",
    "<br/>    \n",
    "    \n",
    "–£–≤–∏–¥–µ–≤ —É —Ç–µ–±—è –Ω–µ—Ç–æ—á–Ω–æ—Å—Ç—å, –≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑ —è –ª–∏—à—å —É–∫–∞–∂—É –Ω–∞ –µ–µ –Ω–∞–ª–∏—á–∏–µ –∏ –¥–∞–º —Ç–µ–±–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Å–∞–º–æ–º—É –Ω–∞–π—Ç–∏ –∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –µ–µ. –ù–∞ —Ä–µ–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç–µ —Ç–≤–æ–π —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –±—É–¥–µ—Ç –ø–æ—Å—Ç—É–ø–∞—Ç—å —Ç–∞–∫–∂–µ, –∏ —è –ø—ã—Ç–∞—é—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ–±—è –∏–º–µ–Ω–Ω–æ –∫ —Ä–∞–±–æ—Ç–µ –¥–∞—Ç–∞—Å–∞–µ–Ω—Ç–∏—Å—Ç–æ–º. –ù–æ –µ—Å–ª–∏ —Ç—ã –ø–æ–∫–∞ –Ω–µ —Å–ø—Ä–∞–≤–∏—à—å—Å—è —Å —Ç–∞–∫–æ–π –∑–∞–¥–∞—á–µ–π - –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–µ —è –¥–∞–º –±–æ–ª–µ–µ —Ç–æ—á–Ω—É—é –ø–æ–¥—Å–∫–∞–∑–∫—É!ü§ì\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞\" data-toc-modified-id=\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞</a></span></li><li><span><a href=\"#–û–±—É—á–µ–Ω–∏–µ\" data-toc-modified-id=\"–û–±—É—á–µ–Ω–∏–µ-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>–û–±—É—á–µ–Ω–∏–µ</a></span></li><li><span><a href=\"#–í—ã–≤–æ–¥—ã\" data-toc-modified-id=\"–í—ã–≤–æ–¥—ã-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>–í—ã–≤–æ–¥—ã</a></span></li><li><span><a href=\"#–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏\" data-toc-modified-id=\"–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>–ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–µ–∫—Ç –¥–ª—è ¬´–í–∏–∫–∏—à–æ–ø¬ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω ¬´–í–∏–∫–∏—à–æ–ø¬ª –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å. –¢–µ–ø–µ—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∏–∫–∏-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. –¢–æ –µ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–≤–æ–∏ –ø—Ä–∞–≤–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö. –ú–∞–≥–∞–∑–∏–Ω—É –Ω—É–∂–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é. \n",
    "\n",
    "–û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ. –í –≤–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–æ–∫.\n",
    "\n",
    "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75. \n",
    "\n",
    "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞**\n",
    "\n",
    "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.\n",
    "2. –û–±—É—á–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏. \n",
    "3. –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã.\n",
    "\n",
    "–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å *BERT* –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å.\n",
    "\n",
    "**–û–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö**\n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —Ñ–∞–π–ª–µ `toxic_comments.csv`. –°—Ç–æ–ª–±–µ—Ü *text* –≤ –Ω—ë–º —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è, –∞ *toxic* ‚Äî —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:</b> \n",
    "    \n",
    "–í–∏–∂—É —Ç–≤–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞. –ú–æ–ª–æ–¥–µ—Ü! –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç —Ç–µ–±–µ —Ä–∞—Å—Å—Ç–∞–≤–ª—è—Ç—å –∞–∫—Ü–µ–Ω—Ç—ã –≤ –≤—ã–≤–æ–¥–∞—Ö\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm #v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'–ü–æ–ª–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ–ø—É—Å–∫–∏:\n",
      "text     0\n",
      "toxic    0\n",
      "dtype: int64\n",
      "\n",
      "–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv', index_col = 0)\n",
    "display(data)\n",
    "display(f'–ü–æ–ª–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {data.duplicated().sum()}')\n",
    "print(f'–ü—Ä–æ–ø—É—Å–∫–∏:\\n{data.isnull().sum()}\\n\\n–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:</b> –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∫–æ—Ä—Ä–µ—Ç–∫–Ω–æ. –ú–æ–ª–æ–¥–µ—Ü, —á—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ—à—å –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—á–∏—Å—Ç–∫–∞ –∏ –ª–µ–º–º–∏—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def text2(text):\n",
    "#     text = re.sub(r'[^a-zA-z ]', ' ', text.lower())\n",
    "#     text = [word for word in nltk.word_tokenize(text) if word not in stop_words]\n",
    "#     return ' '.join([lemmatizer.lemmatize(word) for word in text])\n",
    "\n",
    "# data['text2'] = data['text'].apply(text2)\n",
    "# data.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞   <a class=\"tocSkip\"></h2>\n",
    "    \n",
    "<b>–ù–∞ –¥–æ—Ä–∞–±–æ—Ç–∫—Éü§î:</b>\n",
    "   \n",
    "    \n",
    "–ù—É–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å WordNetLemmatizer() (+POS —Ç–µ–≥) –∏–ª–∏ SpaCy. \n",
    "    \n",
    "–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞ –º–æ–∂–Ω–æ –≤–∑—è—Ç—å –∏–∑ —Ç—Ä–µ–Ω–∞–∂–µ—Ä–∞. **–û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é –º—ã –¥–æ–ª–∂–Ω—ã –ø—Ä–∏–º–µ–Ω—è—Ç—å –∫ –∫–∞–∂–¥–æ–º—É —Ç–æ–∫–µ–Ω—É (—Å–ª–æ–≤—É –≤ —Ç–µ–∫—Å—Ç–µ). made –≤ –Ω—É–ª–µ–≤–æ–π —Å—Ç—Ä–æ–∫–µ –¥–æ–ª–∂–Ω–æ —Å—Ç–∞—Ç—å make, –∞ are –≤ —á–µ—Ç–≤–µ—Ä—Ç–æ–π —Å—Ç—Ä–æ–∫–µ —Å—Ç–∞—Ç—å be**\n",
    "    \n",
    "    \n",
    "–î–µ–ª—é—Å—å —Å —Ç–æ–±–æ–π –ø–æ–ª–µ–∑–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏:\n",
    "        \n",
    "  \n",
    " https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/\n",
    "        \n",
    "–•–æ—á—É –æ–±—Ä–∞—Ç–∏—Ç—å —Ç–≤–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –∫–æ–¥ –∏–∑ –≤—ã—à–µ—É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–æ–ª—å—à–µ, —á–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –≤–æ—Ç –∏–∑ —ç—Ç–æ–≥–æ —Ç–æ–ø–∏–∫–∞\n",
    "    \n",
    "https://stackoverflow.com/questions/50992974/nltk-wordnetlemmatizer-not-lemmatizing-as-expected    \n",
    "        \n",
    "       \n",
    "    \n",
    "    \n",
    "<div class=\"alert alert-warning\">    \n",
    "<b>–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏üí°:</b> \n",
    "   \n",
    "\n",
    "\n",
    "- –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é –º–æ–∂–Ω–æ –±—ã–ª–æ —Å–¥–µ–ª–∞—Ç—å —Å –ø–æ–º–æ—â—å—é SpaCy –ª–µ–º–º–∞—Ç–∏–∑–∞—Ç–æ—Ä–æ–º –∏ –ø—Ä—è–º–æ —Å–∫–∞–∂–µ–º –∫–∞–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –æ–Ω –±–æ–ª–µ–µ —É–¥–æ–±–µ–Ω –∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª–µ–Ω, –Ω–µ –Ω—É–∂–Ω–æ –∑–∞–º–æ—Ä–∞—á–∏–≤–∞—Ç—å—Å—è —Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π –∏ —É—á—ë—Ç–æ–º –ø–æ—Å —Ç–µ–≥–æ–≤\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- –ß—Ç–æ–±—ã —Å—ç–∫–æ–Ω–æ–º–∏—Ç—å –≤—Ä–µ–º—è, –∏ —É–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –≤—Å—ë –æ—Ç—Ä–∞–±–æ—Ç–∞–ª–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –±–µ—Ä—ë—à—å –ø–∞—Ä–æ—á–∫—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —Å–æ–∑–¥–∞—ë—à—å dataframe\n",
    "    \n",
    "    \n",
    "    sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "    sentence2 = \"you should be ashamed of yourself went worked\"\n",
    "    df_my = pd.DataFrame([sentence1, sentence2], columns = ['text'])\n",
    "    print(df_my)\n",
    "\n",
    "\n",
    "    print(df_my['text'].apply(func))\n",
    "    \n",
    "    \n",
    "    \n",
    "–ò —Ç–µ—Å—Ç–∏—Ä—É–µ—à—å –Ω–µ –Ω–µ–º, –¥–æ–ª–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å—Å—è \n",
    "    \n",
    "    \n",
    "    \n",
    "    striped  ------> strip, went -------> go  \n",
    "\n",
    "\n",
    "\n",
    "–ï—Å–ª–∏ –≤—Å—ë –ø–æ–ª—É—á–∏–ª–æ—Å—å, —Ç–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞ –≤—Å—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  The striped bats are hanging on their feet for...\n",
      "1      you should be ashamed of yourself went worked \n",
      "\n",
      "0    strip bat hang feet best\n",
      "1             ashamed go work\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# v2\n",
    "def text3(text):\n",
    "    text = re.sub(r'[^a-zA-z ]', ' ', text.lower())\n",
    "    text = [word for word in nltk.word_tokenize(text) if word not in stop_words]\n",
    "    return ' '.join([lemmatizer.lemmatize(word, 'v') for word in text])\n",
    "\n",
    "sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "sentence2 = \"you should be ashamed of yourself went worked\"\n",
    "df_my = pd.DataFrame([sentence1, sentence2], columns = ['text'])\n",
    "print(df_my,'\\n')\n",
    "print(df_my['text'].apply(text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 159292/159292 [01:17<00:00, 2052.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aww match background colour seemingly stick th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>make real suggestions improvement wonder secti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>second time ask view completely contradict cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>ashamed horrible thing put talk page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>spitzer umm theres actual article prostitution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>look like actually put speedy first version de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>really think understand come idea bad right aw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text2\n",
       "0       explanation edit make username hardcore metall...\n",
       "1       aww match background colour seemingly stick th...\n",
       "2       hey man really try edit war guy constantly rem...\n",
       "3       make real suggestions improvement wonder secti...\n",
       "4                           sir hero chance remember page\n",
       "...                                                   ...\n",
       "159446  second time ask view completely contradict cov...\n",
       "159447               ashamed horrible thing put talk page\n",
       "159448  spitzer umm theres actual article prostitution...\n",
       "159449  look like actually put speedy first version de...\n",
       "159450  really think understand come idea bad right aw...\n",
       "\n",
       "[159292 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2\n",
    "tqdm.pandas()\n",
    "data['text2'] = data['text'].progress_apply(text3)\n",
    "data.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['make']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# v2\n",
    "print(re.findall(r'ma[dk]e| are | be ',data.iloc[0, 2]))\n",
    "print(re.findall(r'ma[dk]e| are | be ',data.iloc[4, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2\n",
    "lemmatizer.lemmatize('are', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'be']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2\n",
    "[word for word in stop_words if word in ['are', 'be']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style=\"border-radius: 10px; box-shadow: 2px 2px 2px; border: 1px solid; padding: 10px\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞ v2: <a class=\"tocSkip\"></a> </h2>\n",
    "\n",
    "–¢–µ–≥ –ø–æ–ø—Ä–∞–≤–∏–ª. –ü–æ –ø–æ–≤–æ–¥—É \"`–û–±—Ä–∞—Ç–∏ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—é –º—ã –¥–æ–ª–∂–Ω—ã –ø—Ä–∏–º–µ–Ω—è—Ç—å –∫ –∫–∞–∂–¥–æ–º—É —Ç–æ–∫–µ–Ω—É (—Å–ª–æ–≤—É –≤ —Ç–µ–∫—Å—Ç–µ)`\": –Ω–µ –ø–æ–Ω—è–ª, —á—Ç–æ –Ω–µ —Ç–∞–∫? –Ø –∂ –≤ –∏—Ç—Ä–µ—Ä–∞—Ç–æ—Ä–µ –∏–º–µ–Ω–Ω–æ —Ç–∞–∫ –∏ –¥–µ–ª–∞–ª: `[lemmatizer.lemmatize(word) for word in text]`.  \n",
    "\n",
    "–ü–æ –ø–æ–≤–æ–¥—É –ø—Ä–∏–º–µ—Ä–∞ –∏–∑ 4-–π —Å—Ç—Ä–æ–∫–∏: are –∏ be –≤ —Å—Ç–æ–ø-—Å–ø–∏—Å–∫–µ, –ø–æ—ç—Ç–æ–º—É –¥–æ –∏—Ö –ª–µ–º–º–∏—Ç–∏–∑–∞—Ü–∏–∏ –¥–µ–ª–æ –ø—Ä–æ—Å—Ç–æ –Ω–µ –¥–æ–π–¥–µ—Ç.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ 2 <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:</b> –í—Å–µ —Ö–æ—Ä–æ—à–æ, –ø–æ–Ω—è–ª —Ç–µ–±—è\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:</b>\n",
    "    \n",
    "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å progress_apply. –î–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –≤—Ä–µ–º–µ–Ω–∏ –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏, –ø–æ—Å–∫–æ–ª—å–∫—É –ø—Ä–æ—Ü–µ—Å—Å –¥–ª–∏—Ç–µ–ª—å–Ω—ã–π, –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞. –†–∞–∑–ª–∏—á–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∑–¥–µ—Å—å: \n",
    "    \n",
    "https://habr.com/ru/post/483400/ \n",
    "    \n",
    "–ü—Ä–∏–º–µ—Ä:\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    tqdm.pandas()\n",
    "    data['lemm_text'] = data['text'].progress_apply(lemmatize)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ 2 <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (111504, 2)\n",
      "Test data shape: (47788, 2)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data.iloc[:,1:], test_size = 0.3, stratify = data.toxic, random_state=1)\n",
    "print('Train data shape:', train.shape)\n",
    "print('Test data shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:</b>\n",
    "    \n",
    "–†–∞–∑–±–∏–µ–Ω–∏–µ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ –≤–µ—Ä–Ω–æ. –û—Ç–ª–∏—á–Ω–æ, —á—Ç–æ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä –ø—Ä–∏–º–µ–Ω–µ–Ω –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['f1', 'params', 'model', 'label'])\n",
    "\n",
    "def training(*, model, params, label=None):\n",
    "    global result\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(min_df = 1)), # TFIDF –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
    "        ('model', model)])\n",
    "    grid = GridSearchCV(pipeline, cv = 5, n_jobs = -1, param_grid = params,\n",
    "                        scoring = 'f1', verbose = False)\n",
    "    grid.fit(train.text2, train.toxic)\n",
    "    exist_hyper=[]\n",
    "    for i in list(grid.get_params().keys()):\n",
    "        if 'estimator__model__' in i:\n",
    "            exist_hyper.append(i.replace('estimator__model__', '')) #v1\n",
    "    display(f\"–¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {exist_hyper}\")\n",
    "    result.loc[len(result)] = pd.Series({'f1': grid.best_score_,\n",
    "                     'params': grid.best_params_,\n",
    "                     'model': grid.best_estimator_,\n",
    "                     'label': label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"–¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: ['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 49s, sys: 4min 53s, total: 9min 43s\n",
      "Wall time: 9min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training(model=LogisticRegression(),\n",
    "            params={\"model__C\":[0.1, 1.0, 10.0], \"model__penalty\":[\"l2\"]},\n",
    "            label='LogisticRegression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:</b>\n",
    "    \n",
    "–õ–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å + –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –° - —ç—Ç–æ —Å–µ–∫—Ä–µ—Ç —É—Å–ø–µ—Ö–∞ –≤ —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ. –ü–æ—ç—Ç–æ–º—É –µ—Å—Ç—å —Å–º—ã—Å–ª  –ø–æ—Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π (–ø–µ–Ω–∞–ª—Ç–∏ l1/l2 + –ø–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –° –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 5-15). –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–∏–ª–∏ –ª—é–±–æ–π –¥—Ä—É–≥–æ–π –ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏) —Ä–∞—Å–∫—Ä—ã—Ç—å—Å—è –≤ –ø–æ–ª–Ω—É—é —Å–∏–ª—É\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"–¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: ['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 27s, sys: 22min 7s, total: 45min 34s\n",
      "Wall time: 45min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# v2\n",
    "training(model=LogisticRegression(),\n",
    "            params={\"model__C\": range(5,16), \"model__penalty\":[\"l1\", \"l2\"]},\n",
    "            label='LogisticRegression v.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"–¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: ['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 32s, sys: 5.4 s, total: 2min 37s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training(model=DecisionTreeClassifier(),\n",
    "            params={'model__criterion':['gini','entropy'],'model__max_depth':[2,4,6]},\n",
    "            label='DecisionTreeClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"–¥–æ—Å—Ç—É–ø–Ω—ã–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã: ['logging_level']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43min 25s, sys: 1min 13s, total: 44min 38s\n",
      "Wall time: 45min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training(model=CatBoostClassifier(logging_level='Silent'),\n",
    "            params={'model__depth': [4,6],\n",
    "                 'model__learning_rate' : [0.01,0.03],\n",
    "                  'model__iterations' : [10, 50]},\n",
    "            label='CatBoostClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>params</th>\n",
       "      <th>model</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774350</td>\n",
       "      <td>{'model__C': 10.0, 'model__penalty': 'l2'}</td>\n",
       "      <td>(TfidfVectorizer(), LogisticRegression(C=10.0))</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775407</td>\n",
       "      <td>{'model__C': 15, 'model__penalty': 'l2'}</td>\n",
       "      <td>(TfidfVectorizer(), LogisticRegression(C=15))</td>\n",
       "      <td>LogisticRegression v.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.558517</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>(TfidfVectorizer(), DecisionTreeClassifier(max...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.527200</td>\n",
       "      <td>{'model__depth': 6, 'model__iterations': 50, '...</td>\n",
       "      <td>(TfidfVectorizer(), &lt;catboost.core.CatBoostCla...</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1                                             params  \\\n",
       "0  0.774350         {'model__C': 10.0, 'model__penalty': 'l2'}   \n",
       "1  0.775407           {'model__C': 15, 'model__penalty': 'l2'}   \n",
       "2  0.558517  {'model__criterion': 'gini', 'model__max_depth...   \n",
       "3  0.527200  {'model__depth': 6, 'model__iterations': 50, '...   \n",
       "\n",
       "                                               model                   label  \n",
       "0    (TfidfVectorizer(), LogisticRegression(C=10.0))      LogisticRegression  \n",
       "1      (TfidfVectorizer(), LogisticRegression(C=15))  LogisticRegression v.2  \n",
       "2  (TfidfVectorizer(), DecisionTreeClassifier(max...  DecisionTreeClassifier  \n",
       "3  (TfidfVectorizer(), <catboost.core.CatBoostCla...      CatBoostClassifier  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>params</th>\n",
       "      <th>model</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775407</td>\n",
       "      <td>{'model__C': 15, 'model__penalty': 'l2'}</td>\n",
       "      <td>(TfidfVectorizer(), LogisticRegression(C=15))</td>\n",
       "      <td>LogisticRegression v.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.774350</td>\n",
       "      <td>{'model__C': 10.0, 'model__penalty': 'l2'}</td>\n",
       "      <td>(TfidfVectorizer(), LogisticRegression(C=10.0))</td>\n",
       "      <td>LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.558517</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>(TfidfVectorizer(), DecisionTreeClassifier(max...</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.527200</td>\n",
       "      <td>{'model__depth': 6, 'model__iterations': 50, '...</td>\n",
       "      <td>(TfidfVectorizer(), &lt;catboost.core.CatBoostCla...</td>\n",
       "      <td>CatBoostClassifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1                                             params  \\\n",
       "1  0.775407           {'model__C': 15, 'model__penalty': 'l2'}   \n",
       "0  0.774350         {'model__C': 10.0, 'model__penalty': 'l2'}   \n",
       "2  0.558517  {'model__criterion': 'gini', 'model__max_depth...   \n",
       "3  0.527200  {'model__depth': 6, 'model__iterations': 50, '...   \n",
       "\n",
       "                                               model                   label  \n",
       "1      (TfidfVectorizer(), LogisticRegression(C=15))  LogisticRegression v.2  \n",
       "0    (TfidfVectorizer(), LogisticRegression(C=10.0))      LogisticRegression  \n",
       "2  (TfidfVectorizer(), DecisionTreeClassifier(max...  DecisionTreeClassifier  \n",
       "3  (TfidfVectorizer(), <catboost.core.CatBoostCla...      CatBoostClassifier  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_result = result.sort_values('f1', ascending=False).iloc[0]\n",
    "result.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:  </b>\n",
    "    \n",
    "–ú–æ–ª–æ–¥–µ—Ü, —á—Ç–æ –ø—Ä–æ–±—É–µ—à—å —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤ —ç—Ç–æ–º —à–∞–≥–µ)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7715398716773602"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = best_result.model.predict(test.text2)\n",
    "f1_score(predict_test, test.toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>–í—Å–µ –æ—Ç–ª–∏—á–Ω–æ!üëç:</b> \n",
    "    \n",
    "–ù–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –ø–æ–ª—É—á–µ–Ω–æ —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å - LogisticRegression. –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑–∞–ª–∞ –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ F1 –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ –∏ –Ω–∞ –æ–±—É—á–∞—é—â–µ–π –∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid Chocolate 2px; padding: 40px\">\n",
    "\n",
    "<h2> –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ <a class=\"tocSkip\"> </h2>    \n",
    "  \n",
    "–£ –º–µ–Ω—è —Å–ª–æ–∂–∏–ª–æ—Å—å —Ö–æ—Ä–æ—à–µ–µ –æ–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ –æ –ø—Ä–æ–µ–∫—Ç–µ, —Ç–µ–±–µ —É–¥–∞–ª–æ—Å—å –Ω–µ–ø–ª–æ—Ö–æ —Å–ø—Ä–∞–≤–∏—Ç—å—Å—è —Å —ç—Ç–∏–º –ø—Ä–æ–µ–∫—Ç–æ–º. –ú–æ–ª–æ–¥–µ—Ü! –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, –∏–∑—É—á–µ–Ω –∫–∞–∂–¥—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä. –ü–ø–æ—Å—Ç—Ä–æ–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –æ—Ü–µ–Ω–µ–Ω–æ –∏—Ö –∫–∞—á–µ—Å—Ç–≤–æ. –û—Å–º—ã—Å–ª–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ –∏ –¥–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ - –º–Ω–æ–≥–æ–µ —É–¥–∞–ª–æ—Å—å –∫–∞–∫ –Ω–∞–¥–æ)\n",
    "    \n",
    "–û—Ç–º–µ—á—É –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞üôÇ:\n",
    "    \n",
    "- –≤ —Ö–æ–¥–µ –ø—Ä–æ–µ–∫—Ç–∞ –≤—Å—Ç—Ä–µ—á–∞–ª–∏—Å—å  —Ñ—É–Ω–∫—Ü–∏–∏, –ø–æ–º–æ–≥–∞—é—â–∏–µ –∏–∑–±–∞–≤–∏—Ç—å—Å—è –æ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞;\n",
    "- —Ö–æ—Ä–æ—à–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è;\n",
    "- –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –ø–æ–∏—Å–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "    \n",
    "–ï—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–º–µ–Ω—Ç–æ–≤ –≤—Å–µ–≥–æ, –Ω–∞ –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–æ–∏—Ç –µ—â—ë —Ä–∞–∑ –≤–∑–≥–ª—è–Ω—É—Ç—å, —è —É–∫–∞–∑–∞–ª –∏—Ö –≤ –º–æ–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö –ø–æ —Ö–æ–¥—É –ø—Ä–æ–µ–∫—Ç–∞. –ü—Ä–µ–¥–ª–∞–≥–∞—é —Ç–µ–±–µ –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–æ–µ–∫—Ç –ø–æ –º–æ–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º, —á—Ç–æ–±—ã –¥–æ–≤–µ—Å—Ç–∏ –µ–≥–æ –¥–æ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–∞.\n",
    "    \n",
    "–ï—Å–ª–∏ –±—É–¥—É—Ç –≤–æ–ø—Ä–æ—Å—ã, –æ–±—Ä–∞—â–∞–π—Å—è, —Å —É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ–º –Ω–∞ –Ω–∏—Ö –æ—Ç–≤–µ—á—É.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid Chocolate 2px; padding: 40px\">\n",
    "\n",
    "\n",
    "<h2> –ò—Ç–æ–≥–æ–≤—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ 2 <a class=\"tocSkip\"> </h2>    \n",
    "  \n",
    "–¢–µ–ø–µ—Ä—å –ø–æ—á—Ç–∏ –∏–¥–µ–∞–ª—å–Ω–æ. –ü—Ä–∏–Ω–∏–º–∞—é —Ä–∞–±–æ—Ç—É)\n",
    "    \n",
    "–ï—Å–ª–∏ —Ö–æ—á–µ—à—å –ª—É—á—à–µ —Ä–∞–∑–æ–±—Ä–∞—Ç—å—Å—è –≤ —Ç–µ–º–µ, —Ç–æ –º–æ–≥—É –ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞—Ç—å —Ç–µ–±–µ: \n",
    "    \n",
    "https://huggingface.co/transformers/model_doc/bert.html\n",
    "    \n",
    "https://t.me/renat_alimbekov\n",
    "    \n",
    "https://colah.github.io/posts/2015-08-Understanding-LSTMs/ - –ü—Ä–æ LSTM\n",
    "    \n",
    "https://web.stanford.edu/~jurafsky/slp3/10.pdf - –ø—Ä–æ —ç–Ω–∫–æ–¥–µ—Ä-–¥–µ–∫–æ–¥–µ—Ä –º–æ–¥–µ–ª–∏, —ç—Ç–µ–Ω—à–µ–Ω—ã\n",
    "    \n",
    "https://pytorch.org/tutorials/beginner/transformer_tutorial.html - –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –≥–∞–π–¥ –ø–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—É –æ—Ç —Å–æ–∑–¥–∞—Ç–µ–ª–µ–π pytorch\n",
    "    \n",
    "https://transformer.huggingface.co/ - –ø–æ–±–æ–ª—Ç–∞—Ç—å —Å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–º\n",
    "    \n",
    "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏: allennlp, fairseq, transformers, tensorflow-text ‚Äî –º–Ω–æ–∂–µ—Å—Ç–≤–æ—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –º–µ—Ç–æ–¥–æ–≤ NLP\n",
    "    \n",
    "Word2Vec https://radimrehurek.com/gensim/models/word2vec.html\n",
    "    \n",
    "    \n",
    "    \n",
    "–í —ç—Ç–æ–º –ø—Ä–æ–µ–∫—Ç–µ –±—ã–ª–∏ –æ—Ç—Ä–∞–±–æ—Ç–∞–Ω—ã –≤—Å–µ –º–æ–º–µ–Ω—Ç—ã. \n",
    "    \n",
    "–£—Å–ø–µ—Ö–æ–≤ —Ç–µ–±–µ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Å–ø—Ä–∏–Ω—Ç–µ!\n",
    "    \n",
    "–†–∞–¥ –±—ã–ª –ø–æ–º–æ—á—å —Ç–µ–±–µ)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook –æ—Ç–∫—Ä—ã—Ç\n",
    "- [x]  –í–µ—Å—å –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫\n",
    "- [x]  –Ø—á–µ–π–∫–∏ —Å –∫–æ–¥–æ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "- [x]  –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã\n",
    "- [x]  –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã\n",
    "- [x]  –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75\n",
    "- [x]  –í—ã–≤–æ–¥—ã –Ω–∞–ø–∏—Å–∞–Ω—ã"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1986,
    "start_time": "2023-10-23T09:40:33.357Z"
   },
   {
    "duration": 2711,
    "start_time": "2023-10-23T09:40:37.630Z"
   },
   {
    "duration": 43,
    "start_time": "2023-10-23T09:41:00.412Z"
   },
   {
    "duration": 937,
    "start_time": "2023-10-23T09:41:37.039Z"
   },
   {
    "duration": 40,
    "start_time": "2023-10-23T09:41:39.544Z"
   },
   {
    "duration": 953,
    "start_time": "2023-10-23T09:42:03.689Z"
   },
   {
    "duration": 48,
    "start_time": "2023-10-23T09:42:05.894Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-23T09:42:39.121Z"
   },
   {
    "duration": 26,
    "start_time": "2023-10-23T09:43:28.660Z"
   },
   {
    "duration": 62,
    "start_time": "2023-10-23T09:44:26.262Z"
   },
   {
    "duration": 61,
    "start_time": "2023-10-23T09:44:40.015Z"
   },
   {
    "duration": 63,
    "start_time": "2023-10-23T09:44:48.546Z"
   },
   {
    "duration": 63,
    "start_time": "2023-10-23T09:44:57.562Z"
   },
   {
    "duration": 63,
    "start_time": "2023-10-23T09:45:04.397Z"
   },
   {
    "duration": 61,
    "start_time": "2023-10-23T09:45:25.459Z"
   },
   {
    "duration": 70,
    "start_time": "2023-10-23T09:45:38.695Z"
   },
   {
    "duration": 1043,
    "start_time": "2023-10-23T09:46:23.827Z"
   },
   {
    "duration": 1233,
    "start_time": "2023-10-23T09:47:16.299Z"
   },
   {
    "duration": 1085,
    "start_time": "2023-10-23T09:47:32.847Z"
   },
   {
    "duration": 1189,
    "start_time": "2023-10-23T09:47:52.184Z"
   },
   {
    "duration": 1213,
    "start_time": "2023-10-23T09:48:10.860Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-23T12:33:09.997Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-23T12:33:25.765Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-23T12:33:47.647Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-23T12:40:32.162Z"
   },
   {
    "duration": 111,
    "start_time": "2023-10-23T12:56:43.965Z"
   },
   {
    "duration": 1749,
    "start_time": "2023-10-23T12:56:54.971Z"
   },
   {
    "duration": 14,
    "start_time": "2023-10-23T12:57:03.970Z"
   },
   {
    "duration": 33,
    "start_time": "2023-10-23T12:57:41.087Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-23T12:57:59.681Z"
   },
   {
    "duration": 383,
    "start_time": "2023-10-23T13:03:11.924Z"
   },
   {
    "duration": 206,
    "start_time": "2023-10-23T13:03:20.788Z"
   },
   {
    "duration": 75498,
    "start_time": "2023-10-23T13:03:38.305Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-23T13:05:00.959Z"
   },
   {
    "duration": 2,
    "start_time": "2023-10-23T13:08:01.035Z"
   },
   {
    "duration": 17,
    "start_time": "2023-10-23T13:08:35.617Z"
   },
   {
    "duration": 25,
    "start_time": "2023-10-23T13:08:44.295Z"
   },
   {
    "duration": 119,
    "start_time": "2023-10-23T13:12:52.728Z"
   },
   {
    "duration": 12,
    "start_time": "2023-10-23T13:13:45.241Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-23T13:13:53.331Z"
   },
   {
    "duration": 1740,
    "start_time": "2023-10-23T13:15:06.757Z"
   },
   {
    "duration": 1326,
    "start_time": "2023-10-23T13:15:08.500Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-23T13:15:09.828Z"
   },
   {
    "duration": 245,
    "start_time": "2023-10-23T13:15:09.836Z"
   },
   {
    "duration": 64581,
    "start_time": "2023-10-23T13:15:10.082Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-23T13:16:14.666Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-23T13:16:14.667Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-23T13:16:14.669Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-23T13:16:14.671Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-23T13:16:14.672Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-23T13:16:14.673Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-23T13:16:14.674Z"
   },
   {
    "duration": 1700,
    "start_time": "2023-10-23T13:16:25.597Z"
   },
   {
    "duration": 1302,
    "start_time": "2023-10-23T13:16:27.299Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-23T13:16:28.603Z"
   },
   {
    "duration": 156,
    "start_time": "2023-10-23T13:16:28.610Z"
   },
   {
    "duration": 76058,
    "start_time": "2023-10-23T13:16:28.768Z"
   },
   {
    "duration": 17,
    "start_time": "2023-10-23T13:17:44.827Z"
   },
   {
    "duration": 29,
    "start_time": "2023-10-23T13:17:44.846Z"
   },
   {
    "duration": 15,
    "start_time": "2023-10-23T13:17:44.877Z"
   },
   {
    "duration": 24,
    "start_time": "2023-10-23T13:17:44.894Z"
   },
   {
    "duration": 98,
    "start_time": "2023-10-23T13:17:44.921Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-23T13:17:45.021Z"
   },
   {
    "duration": 76,
    "start_time": "2023-10-23T13:31:35.192Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-23T13:31:37.988Z"
   },
   {
    "duration": 99,
    "start_time": "2023-10-23T13:51:06.026Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-23T13:51:23.989Z"
   },
   {
    "duration": 124,
    "start_time": "2023-10-23T13:51:27.391Z"
   },
   {
    "duration": 18,
    "start_time": "2023-10-23T13:52:31.359Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-23T13:53:19.663Z"
   },
   {
    "duration": 262939,
    "start_time": "2023-10-23T13:53:22.131Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-23T13:58:11.955Z"
   },
   {
    "duration": 624141,
    "start_time": "2023-10-23T13:58:47.264Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-23T15:19:05.115Z"
   },
   {
    "duration": 98,
    "start_time": "2023-10-23T15:20:20.383Z"
   },
   {
    "duration": 103,
    "start_time": "2023-10-23T15:20:26.251Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-23T15:20:31.288Z"
   },
   {
    "duration": 616558,
    "start_time": "2023-10-23T15:20:38.554Z"
   },
   {
    "duration": 19,
    "start_time": "2023-10-23T15:36:06.202Z"
   },
   {
    "duration": 162814,
    "start_time": "2023-10-23T15:36:16.610Z"
   },
   {
    "duration": 79,
    "start_time": "2023-10-23T15:38:59.426Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-23T15:38:59.506Z"
   },
   {
    "duration": 30,
    "start_time": "2023-10-23T15:43:34.633Z"
   },
   {
    "duration": 2913539,
    "start_time": "2023-10-23T15:43:39.881Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-23T16:32:13.423Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-23T16:37:40.585Z"
   },
   {
    "duration": 1796,
    "start_time": "2023-10-23T16:44:34.285Z"
   },
   {
    "duration": 1358,
    "start_time": "2023-10-23T16:44:36.083Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-23T16:44:37.443Z"
   },
   {
    "duration": 248,
    "start_time": "2023-10-23T16:44:37.456Z"
   },
   {
    "duration": 74637,
    "start_time": "2023-10-23T16:44:37.707Z"
   },
   {
    "duration": 89,
    "start_time": "2023-10-23T16:45:52.346Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-23T16:45:52.438Z"
   },
   {
    "duration": 616565,
    "start_time": "2023-10-23T16:45:52.447Z"
   },
   {
    "duration": 159223,
    "start_time": "2023-10-23T16:56:09.013Z"
   },
   {
    "duration": 1702037,
    "start_time": "2023-10-23T16:58:48.238Z"
   },
   {
    "duration": 14,
    "start_time": "2023-10-23T17:27:10.277Z"
   },
   {
    "duration": 30,
    "start_time": "2023-10-23T17:27:10.292Z"
   },
   {
    "duration": 1408,
    "start_time": "2023-10-23T17:27:10.324Z"
   },
   {
    "duration": 1607,
    "start_time": "2023-10-23T17:27:21.570Z"
   },
   {
    "duration": 1277,
    "start_time": "2023-10-23T17:27:23.179Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-23T17:27:24.458Z"
   },
   {
    "duration": 220,
    "start_time": "2023-10-23T17:27:24.465Z"
   },
   {
    "duration": 73470,
    "start_time": "2023-10-23T17:27:24.687Z"
   },
   {
    "duration": 83,
    "start_time": "2023-10-23T17:28:38.159Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-23T17:28:38.244Z"
   },
   {
    "duration": 608161,
    "start_time": "2023-10-23T17:28:38.253Z"
   },
   {
    "duration": 161606,
    "start_time": "2023-10-23T17:38:46.416Z"
   },
   {
    "duration": 2918476,
    "start_time": "2023-10-23T17:41:28.025Z"
   },
   {
    "duration": 20,
    "start_time": "2023-10-23T18:30:06.503Z"
   },
   {
    "duration": 14,
    "start_time": "2023-10-23T18:30:06.525Z"
   },
   {
    "duration": 1921,
    "start_time": "2023-10-23T18:30:06.541Z"
   },
   {
    "duration": 17,
    "start_time": "2023-10-23T18:40:56.511Z"
   },
   {
    "duration": 1483,
    "start_time": "2023-10-23T18:41:07.152Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-25T01:01:44.710Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-25T01:02:22.527Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-25T01:02:28.474Z"
   },
   {
    "duration": 12,
    "start_time": "2023-10-25T01:03:37.555Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-25T01:03:40.753Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-25T01:05:12.831Z"
   },
   {
    "duration": 11,
    "start_time": "2023-10-25T01:06:10.533Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-25T01:11:51.475Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-25T01:12:11.729Z"
   },
   {
    "duration": 239,
    "start_time": "2023-10-25T01:13:47.361Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-25T01:15:21.800Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-25T01:15:32.492Z"
   },
   {
    "duration": 10,
    "start_time": "2023-10-25T01:16:05.477Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-25T01:17:03.584Z"
   },
   {
    "duration": 75669,
    "start_time": "2023-10-25T01:29:38.477Z"
   },
   {
    "duration": 78603,
    "start_time": "2023-10-25T01:35:38.860Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-25T01:36:57.465Z"
   },
   {
    "duration": 141,
    "start_time": "2023-10-25T01:37:19.794Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-25T01:37:33.543Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-25T01:39:45.304Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-25T01:40:52.957Z"
   },
   {
    "duration": 13,
    "start_time": "2023-10-25T01:41:28.539Z"
   },
   {
    "duration": 12,
    "start_time": "2023-10-25T01:41:36.385Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-25T01:41:42.418Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-25T01:42:38.653Z"
   },
   {
    "duration": 7,
    "start_time": "2023-10-25T01:42:56.582Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-25T01:43:02.179Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-25T01:43:13.656Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-25T01:43:42.973Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-25T01:44:04.728Z"
   },
   {
    "duration": 1673,
    "start_time": "2023-10-25T01:48:26.357Z"
   },
   {
    "duration": 1218,
    "start_time": "2023-10-25T01:48:28.032Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-25T01:48:29.252Z"
   },
   {
    "duration": 125,
    "start_time": "2023-10-25T01:48:29.261Z"
   },
   {
    "duration": 8203,
    "start_time": "2023-10-25T01:48:29.388Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.593Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.594Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.595Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.597Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.598Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.599Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.600Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.601Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.602Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.603Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.604Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T01:48:37.606Z"
   },
   {
    "duration": 1734,
    "start_time": "2023-10-25T01:48:59.787Z"
   },
   {
    "duration": 1218,
    "start_time": "2023-10-25T01:49:01.522Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-25T01:49:02.742Z"
   },
   {
    "duration": 125,
    "start_time": "2023-10-25T01:49:02.749Z"
   },
   {
    "duration": 3,
    "start_time": "2023-10-25T01:49:02.875Z"
   },
   {
    "duration": 1267,
    "start_time": "2023-10-25T01:49:02.880Z"
   },
   {
    "duration": 78318,
    "start_time": "2023-10-25T01:49:04.148Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-25T01:50:22.467Z"
   },
   {
    "duration": 97,
    "start_time": "2023-10-25T01:50:22.473Z"
   },
   {
    "duration": 9,
    "start_time": "2023-10-25T01:50:22.573Z"
   },
   {
    "duration": 638517,
    "start_time": "2023-10-25T01:50:22.584Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-25T02:01:01.103Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T02:01:01.110Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T02:01:01.111Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T02:01:01.113Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T02:01:01.114Z"
   },
   {
    "duration": 0,
    "start_time": "2023-10-25T02:01:01.115Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-25T02:03:05.791Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-25T02:03:20.950Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-25T02:04:28.518Z"
   },
   {
    "duration": 5,
    "start_time": "2023-10-25T02:04:34.955Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-25T02:05:54.036Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-25T02:07:16.231Z"
   },
   {
    "duration": 4,
    "start_time": "2023-10-25T02:09:48.844Z"
   },
   {
    "duration": 1739,
    "start_time": "2023-10-25T02:13:23.059Z"
   },
   {
    "duration": 1231,
    "start_time": "2023-10-25T02:13:24.801Z"
   },
   {
    "duration": 6,
    "start_time": "2023-10-25T02:13:26.034Z"
   },
   {
    "duration": 229,
    "start_time": "2023-10-25T02:13:26.042Z"
   },
   {
    "duration": 2,
    "start_time": "2023-10-25T02:13:26.273Z"
   },
   {
    "duration": 1269,
    "start_time": "2023-10-25T02:13:26.277Z"
   },
   {
    "duration": 77637,
    "start_time": "2023-10-25T02:13:27.548Z"
   },
   {
    "duration": 16,
    "start_time": "2023-10-25T02:14:45.187Z"
   },
   {
    "duration": 34,
    "start_time": "2023-10-25T02:14:45.204Z"
   },
   {
    "duration": 56,
    "start_time": "2023-10-25T02:14:45.239Z"
   },
   {
    "duration": 127,
    "start_time": "2023-10-25T02:14:45.296Z"
   },
   {
    "duration": 8,
    "start_time": "2023-10-25T02:14:45.425Z"
   },
   {
    "duration": 584470,
    "start_time": "2023-10-25T02:14:45.435Z"
   },
   {
    "duration": 2737792,
    "start_time": "2023-10-25T02:24:29.909Z"
   },
   {
    "duration": 157723,
    "start_time": "2023-10-25T03:10:07.703Z"
   },
   {
    "duration": 2714130,
    "start_time": "2023-10-25T03:12:45.428Z"
   },
   {
    "duration": 15,
    "start_time": "2023-10-25T03:57:59.560Z"
   },
   {
    "duration": 32,
    "start_time": "2023-10-25T03:57:59.577Z"
   },
   {
    "duration": 1394,
    "start_time": "2023-10-25T03:57:59.611Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "226px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
